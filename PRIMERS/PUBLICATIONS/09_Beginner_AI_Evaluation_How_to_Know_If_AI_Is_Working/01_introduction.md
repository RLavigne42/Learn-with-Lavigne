# Booklet Title
Beginner AI Evaluation: How to Know If AI Is Working

## Section Title
1. Introduction: How to 'Fact-Check' Your AI

## url_slug
`primer/evaluation-fact-checking`

## Short Question
How can a beginner check whether an AI answer is relevant, believable, and verifiable?

## Long-Form Guidance Question
Provide a practical 'checklist' for a non-technical user on how to evaluate the *quality* of an AI's answer. You *must not* use *any* metrics (`BLEU`, `RAGAS`) or frameworks (`LLM-as-a-judge`, `Evals`). (1) Ask for a 'Beginner's QA Checklist'. (e.g., 'Check 1: The 'Plausibility' Check: Does this *sound* believable, or is it 'too good to be true'?'). (e.g., 'Check 2: The 'Relevance' Check: Did the AI *actually* answer my question, or did it 'change the subject' ('drift')?'). (e.g., 'Check 3: The 'Verification' Check: Can I 'fact-check' this? If the AI provided a 'source' (a 'citation'), *did I click it* and *is the answer actually there*?'). (2) Explain 'Hallucinations' in plain terms (e.g., 'When the AI *confidently makes things up* because it's a 'prediction-engine', not a 'truth-engine'.'). (3) Explain *how* to 'prompt' for a 'self-critique' (e.g., 'Show the user how to ask: "Are you sure about that? Please double-check your facts and tell me if you made a mistake."').

## JSON Representation
```json
{
  "booklet_title": "Beginner AI Evaluation: How to Know If AI Is Working",
  "section_title": "1. Introduction: How to 'Fact-Check' Your AI",
  "url_slug": "primer/evaluation-fact-checking",
  "short_question": "How can a beginner check whether an AI answer is relevant, believable, and verifiable?",
  "long_form_question": "Provide a practical 'checklist' for a non-technical user on how to evaluate the *quality* of an AI's answer. You *must not* use *any* metrics (`BLEU`, `RAGAS`) or frameworks (`LLM-as-a-judge`, `Evals`). (1) Ask for a 'Beginner's QA Checklist'. (e.g., 'Check 1: The 'Plausibility' Check: Does this *sound* believable, or is it 'too good to be true'?'). (e.g., 'Check 2: The 'Relevance' Check: Did the AI *actually* answer my question, or did it 'change the subject' ('drift')?'). (e.g., 'Check 3: The 'Verification' Check: Can I 'fact-check' this? If the AI provided a 'source' (a 'citation'), *did I click it* and *is the answer actually there*?'). (2) Explain 'Hallucinations' in plain terms (e.g., 'When the AI *confidently makes things up* because it's a 'prediction-engine', not a 'truth-engine'.'). (3) Explain *how* to 'prompt' for a 'self-critique' (e.g., 'Show the user how to ask: \"Are you sure about that? Please double-check your facts and tell me if you made a mistake.\"')."
}
```
